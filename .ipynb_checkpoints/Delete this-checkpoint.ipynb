{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7VNgmJuv8kc_",
   "metadata": {
    "id": "7VNgmJuv8kc_"
   },
   "source": [
    "# Install all necessary modules here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uo9DV6SrYt4j",
   "metadata": {
    "id": "uo9DV6SrYt4j"
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from torchmetrics.detection.mean_ap import MeanAveragePrecision\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import platform\n",
    "import pickle\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from numpy import random\n",
    "from torch.utils.data import DataLoader\n",
    "import albumentations as A\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bf9f74",
   "metadata": {
    "id": "d3bf9f74"
   },
   "source": [
    "# Preparation of milestone three\n",
    "\n",
    "Today we will start preparing the third milestone. The third milestone is to train an object detector to recognize cells. To successfully complete the milestone, you will have to complete the following sub-tasks:\n",
    "- Initialize a pytorch object detector. I'd suggest to choose a RetinaNet or FCOS detection model. More Information can be found [here](https://pytorch.org/vision/stable/models.html#object-detection-instance-segmentation-and-person-keypoint-detection). Since we do not have endless compute power available, we will use a frozen ResNet18 pre-trained on ImageNet as backbone and only train the detection and classification heads of our object detector. So you will have to finde a way to **freeze** the backbone of your detector.\n",
    "- You will have to write a [training and validation/test](https://pytorch.org/tutorials/beginner/basics/optimization_tutorial.html) loop to train your detector. Make sure you measure the convergence of the training by monitoring a detection metric like the [mAP](https://torchmetrics.readthedocs.io/en/stable/detection/mean_average_precision.html). Also, you will have to find a way to select the best model during training based on some metric.\n",
    "- You will have to train your model until convergence using the  class you created for the last milestone. Also you will have to pass your dataset to a dataloader to be able to use multithreading as well as automatic batching.\n",
    "- At the end, you will have to save the **state_dict** of your trained object detector, to be able to reuse it later.\n",
    "\n",
    "Please use a jupyter notebook for coding your training/testing pipeline. In the end, you will have to submit that jupiter notebook at moodle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418e17a1",
   "metadata": {
    "id": "418e17a1"
   },
   "source": [
    "# If you run the notebook in colab, you have to mount the google drive with the images. Proceed as follows:\n",
    "\n",
    "- **First**: Open the following **[link](https://drive.google.com/drive/folders/18P74V8kli6qDZtGBLN-tPrJFu3O2NPEK?usp=sharing)** in a new tab.\n",
    "- **Second**: Add a link to your google Drive.\n",
    "Example: [Link](https://drive.google.com/file/d/1IcFGGIoktPkDj9-4j5IQ3evInn0c2aq-/view?usp=sharing)\n",
    "- **Third**: Run the line of code below\n",
    "- **Fourth**: Grant Google access to your Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brYRbF8idhWa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "brYRbF8idhWa",
    "outputId": "ec0724fe-c855-4524-e622-2df6edc43981"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "# path to the link you created\n",
    "path_to_slides = '/content/gdrive/MyDrive/AgNORs/'\n",
    "# mount the data\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9CkOa6zxbj5Z",
   "metadata": {
    "id": "9CkOa6zxbj5Z"
   },
   "source": [
    "# 1. Initializing the model\n",
    "\n",
    "In this project, we will use a pre-trained RetinaNet model as the backbone for our object detection task. The model and weights can be easily loaded from the torchvision library. It is important to note that the anchor boxes used by the model may need to be adjusted to suit the specific task.\n",
    "\n",
    "The behavior of the RetinaNet model changes depending on whether it is in training or evaluation mode. During training, the model expects both an image and a dictionary of targets as input. It returns a dictionary containing the losses and predictions. During validation, the model only expects images as input and returns the predictions without calculating any losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eIS8iQg3FmN3",
   "metadata": {
    "id": "eIS8iQg3FmN3"
   },
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, annotations_frame,\n",
    "                 path_to_slides,\n",
    "                 crop_size = (128,128),\n",
    "                 pseudo_epoch_length:int = 1000,\n",
    "                 transformations = None):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        if platform.system() == 'Linux':\n",
    "            self.separator = '/'\n",
    "        else:\n",
    "            self.separator = '\\\\'\n",
    "\n",
    "        self.anno_frame = annotations_frame\n",
    "        self.path_to_slides = path_to_slides\n",
    "        self.crop_size = crop_size\n",
    "        self.pseudo_epoch_length = pseudo_epoch_length\n",
    "        \n",
    "        # list which holds annotations of all slides in slide_names in the format\n",
    "        # slide_name, annotation, label, min_x, max_x, min_y, max_y\n",
    "        \n",
    "        self.slide_dict, self.annotations_list = self._initialize()\n",
    "        self.sample_cord_list = self._sample_cord_list()\n",
    "\n",
    "        # set up transformations\n",
    "        self.transformations = transformations\n",
    "        self.transform_to_tensor = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "\n",
    "    def _initialize(self):\n",
    "        # open all images and store them in self.slide_dict with their name as key value\n",
    "        slide_dict = {}\n",
    "        annotations_list = []\n",
    "        for slide in self.anno_frame.filename.unique():\n",
    "            # open slide\n",
    "            slide_dict[slide] =  Image.open(self.path_to_slides + self.separator + slide).convert('RGB')\n",
    "            im_obj = Image.open(self.path_to_slides + self.separator + slide).convert('RGB')\n",
    "            slide_dict[slide] = im_obj\n",
    "            # setting up a list with all bounding boxes\n",
    "            for idx,annotations in self.anno_frame[self.anno_frame.filename == slide][['max_x','max_y','min_x','min_y','label']].iterrows():\n",
    "                annotations_list.append([slide, annotations['label'], annotations['min_x'], annotations['min_y'], annotations['max_x'], annotations['max_y']])\n",
    "\n",
    "        return slide_dict, annotations_list\n",
    "\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        slide, x_cord, y_cord = self.sample_cord_list[index]\n",
    "        x_cord = np.int64(x_cord)\n",
    "        y_cord = np.int64(y_cord)\n",
    "        # load image\n",
    "        img = self.slide_dict[slide].crop((x_cord,y_cord,x_cord + self.crop_size[0],y_cord + self.crop_size[1]))\n",
    "        # transform image\n",
    "        #img = self.transformations(img)\n",
    "        \n",
    "        # load boxes for the image\n",
    "        labels_boxes = self._get_boxes_and_label(slide,x_cord,y_cord)\n",
    "        \n",
    "        labels_boxes = [[i[1] - x_cord, i[2] - y_cord, i[3] - x_cord, i[4] - y_cord] + [i[0]] for i in labels_boxes]\n",
    "        \n",
    "        \n",
    "        # applay transformations\n",
    "        if self.transformations != None:\n",
    "            if len(labels_boxes) > 0:\n",
    "                transformed = self.transformations(image = np.array(img), bboxes = labels_boxes)\n",
    "                boxes = torch.tensor([line[:-1] for line in transformed['bboxes']], dtype = torch.float32)\n",
    "                labels = torch.ones(boxes.shape[0], dtype = torch.int64)\n",
    "                img = self.transform_to_tensor(transformed['image'])\n",
    "                \n",
    "            # check if there is no labeld instance on the image\n",
    "            if len(labels_boxes) == 0:\n",
    "                labels = torch.tensor([0], dtype = torch.int64)\n",
    "                boxes = torch.zeros((0,4),dtype = torch.float32)\n",
    "                img = self.transform_to_tensor(img)\n",
    "\n",
    "        else:\n",
    "            if len(labels_boxes) == 0:\n",
    "                labels = torch.tensor([0], dtype = torch.int64)\n",
    "                boxes = torch.zeros((0,4),dtype = torch.float32)\n",
    "                img = self.transform_to_tensor(img)\n",
    "            else:\n",
    "                # now, you need to change the originale box cordinates to the cordinates of the image\n",
    "                boxes = torch.tensor([line[:-1] for line in labels_boxes],dtype=torch.float32)\n",
    "                labels = torch.ones(boxes.shape[0], dtype = torch.int64)\n",
    "                img = self.transform_to_tensor(img)\n",
    "\n",
    "        target = {\n",
    "            'boxes': boxes,\n",
    "            'labels':labels\n",
    "        }\n",
    "\n",
    "        return img, target\n",
    "        \n",
    "\n",
    "    def _sample_cord_list(self):\n",
    "        # select slides from which to sample an image\n",
    "        slide_names = np.array(list(self.slide_dict.keys()))\n",
    "        slide_indice = random.choice(np.arange(len(slide_names)), size = self.pseudo_epoch_length, replace = True)\n",
    "        slides = slide_names[slide_indice]\n",
    "        # select coordinates from which to load images\n",
    "        # only works if all images have the same size\n",
    "        width,height = self.slide_dict[slides[0]].size\n",
    "        cordinates = random.randint(low = (0,0), high=(width - self.crop_size[0], height - self.crop_size[1]), size = (self.pseudo_epoch_length,2))\n",
    "        return np.concatenate((slides.reshape(-1,1),cordinates), axis = -1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.pseudo_epoch_length\n",
    "\n",
    "    def _get_boxes_and_label(self,slide,x_cord,y_cord):\n",
    "        return [line[1::] for line in self.annotations_list if line[0] == slide and line[2] > x_cord and line [3] > y_cord and line[4] < x_cord + self.crop_size[0] and line[5] < y_cord + self.crop_size[1]]\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        \"\"\"\n",
    "        Since each image may have a different number of objects, we need a collate function (to be passed to the DataLoader).\n",
    "        This describes how to combine these tensors of different sizes. We use lists.\n",
    "        Note: this need not be defined in this Class, can be standalone.\n",
    "        :param batch: an iterable of N sets from __iter__()\n",
    "        :return: a tensor of images, lists of varying-size tensors of bounding boxes, labels, and difficulties\n",
    "        \"\"\"\n",
    "\n",
    "        images = list()\n",
    "        targets = list()\n",
    "\n",
    "        for b in batch:\n",
    "            images.append(b[0])\n",
    "            targets.append(b[1])\n",
    "            \n",
    "        images = torch.stack(images, dim=0)\n",
    "\n",
    "        return images, targets\n",
    "\n",
    "    def trigger_sampling(self):\n",
    "        self.sample_cord_list = self._sample_cord_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_YC7EQDffb92",
   "metadata": {
    "id": "_YC7EQDffb92"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection import RetinaNet\n",
    "from torchvision.models.detection.anchor_utils import AnchorGenerator\n",
    "from torchvision.models import MobileNet_V2_Weights\n",
    "\n",
    "# the size of your crops\n",
    "#size = 256\n",
    "\n",
    "# load a pre-trained model for classification and return\n",
    "# only the features\n",
    "backbone = torchvision.models.mobilenet_v2(weights=MobileNet_V2_Weights.DEFAULT).features\n",
    "\n",
    "# RetinaNet needs to know the number of\n",
    "# output channels in a backbone. For mobilenet_v2, it's 1280,\n",
    "# so we need to add it here\n",
    "backbone.out_channels = 1280\n",
    "# let's make the network generate 5 x 3 anchors per spatial\n",
    "# location, with 5 different sizes and 3 different aspect\n",
    "# ratios. We have a Tuple[Tuple[int]] because each feature\n",
    "# map could potentially have different sizes and\n",
    "# aspect ratios\n",
    "anchor_generator = AnchorGenerator(\n",
    "     sizes=((32, 64, 128, 256, 512),),\n",
    "     aspect_ratios=((0.5, 1.0, 2.0),)\n",
    ")\n",
    "# put the pieces together inside a RetinaNet model\n",
    "model = RetinaNet(backbone,\n",
    "                  num_classes=2,\n",
    "                  anchor_generator=anchor_generator)\n",
    "\n",
    "# freeze backbone\n",
    "# for p in model.backbone.parameters():\n",
    "#   p.requires_grad = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ryYVXb8Hf-",
   "metadata": {
    "id": "c0ryYVXb8Hf-"
   },
   "source": [
    "# 2. Setting up an optimzer, a detection metric and the train and validation dataloaders\n",
    "\n",
    "To train the object detector, it is necessary to select an appropriate optimizer. Additionally, the torchmetrics class needs to be instantiated before it can be used for evaluation or tracking metrics during training.\n",
    "Additionally, initialize a training and validation dataloader your dataset. For more information on how to set up your dataloaders have a look [here](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4iNlBnCU8pX3",
   "metadata": {
    "id": "4iNlBnCU8pX3"
   },
   "outputs": [],
   "source": [
    "# add your code\n",
    "\n",
    "# initialize dataset\n",
    "annotation_frame = pickle.load(open('/content/gdrive/MyDrive/AgNORs/annotation_frame.p','rb'))\n",
    "path_to_images = '/content/gdrive/MyDrive/AgNORs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "svqjF34SGm_C",
   "metadata": {
    "id": "svqjF34SGm_C"
   },
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "num_workers = 2\n",
    "num_samples = 250\n",
    "# train val split\n",
    "imgs = annotation_frame.filename.unique()\n",
    "train_imgs = imgs[np.random.choice(np.arange(len(imgs)),size = int(0.75 * len(imgs)), replace = False)]\n",
    "val_imgs = [i for i in imgs if i not in train_imgs]\n",
    "\n",
    "# set up transforms\n",
    "transform = A.Compose([\n",
    "    A.HorizontalFlip(p=0.3),\n",
    "    A.RandomBrightnessContrast(p=0.3),\n",
    "    A.Blur(p=0.3),\n",
    "    A.ColorJitter(p=0.3),\n",
    "    A.GaussNoise(p=0.1)\n",
    "], bbox_params=A.BboxParams(format='pascal_voc'))\n",
    "\n",
    "train_df = annotation_frame[annotation_frame.filename.isin(train_imgs)]\n",
    "val_df = annotation_frame[annotation_frame.filename.isin(val_imgs)]\n",
    "\n",
    "train_ds = Dataset(annotations_frame = train_df,\n",
    "                   path_to_slides = path_to_images,\n",
    "                   crop_size = (256,256),\n",
    "                   pseudo_epoch_length=num_samples,\n",
    "                   transformations=transform)\n",
    "val_ds = Dataset(annotations_frame = val_df,\n",
    "                   path_to_slides = path_to_images,\n",
    "                   crop_size = (256,256),\n",
    "                 pseudo_epoch_length=num_samples,\n",
    "                 transformations = transform)\n",
    "\n",
    "train_dl = DataLoader(train_ds,\n",
    "                      batch_size = batch_size,\n",
    "                      num_workers = num_workers,\n",
    "                      collate_fn = train_ds.collate_fn)\n",
    "val_dl = DataLoader(val_ds,\n",
    "                    batch_size = batch_size,\n",
    "                    num_workers = num_workers,\n",
    "                    collate_fn = val_ds.collate_fn)\n",
    "\n",
    "# free some space\n",
    "del val_ds\n",
    "del train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "I_p0qQj1KXLU",
   "metadata": {
    "id": "I_p0qQj1KXLU"
   },
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "learning_rate = 1e-4\n",
    "\n",
    "# Optimizer\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = optim.SGD(params=params, lr=learning_rate, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "I2s7huwv8s72",
   "metadata": {
    "id": "I2s7huwv8s72"
   },
   "source": [
    "#3. Train and validation loop\n",
    "\n",
    "Please write two functions, one for training and one for evaluating your object detector. Use these functions to train the detector for a few epochs. During training, track both the training losses and validation metrics to monitor the model's performance. Save the best detector as observerd by the validation metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NQ12Ch249J3_",
   "metadata": {
    "id": "NQ12Ch249J3_"
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(train_loader, model, optimizer, device:str = 'cpu', epoch:int = 0):\n",
    "    running_loss = 0.0\n",
    "\n",
    "    loss_classifier = 0.0\n",
    "    loss_box_reg = 0.0\n",
    "\n",
    "    # switch to train mode\n",
    "    if not model.training:\n",
    "        model.train()\n",
    "    # iterating over batches in train_loader\n",
    "    for i, (images,targets) in tqdm(enumerate(train_loader,0), total = np.ceil(train_loader.dataset.__len__() / train_loader.batch_size)):\n",
    "\n",
    "        images = images.to(device)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        loss_dict = model(images, targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # log losses\n",
    "        loss_classifier += loss_dict['classification'].detach().to('cpu').numpy()\n",
    "        loss_box_reg += loss_dict['bbox_regression'].detach().to('cpu').numpy()\n",
    "\n",
    "        running_loss += losses\n",
    "        \n",
    "        # print every 100 Minibatches\n",
    "        if i % 5 == 0:\n",
    "            print(f\"Epoch: {epoch + 1}, overall loss train: {running_loss/(i + 1 * train_loader.batch_size):.4f}\", end='\\r')\n",
    "    \n",
    "    return running_loss / (i + 1 * train_loader.batch_size)\n",
    "\n",
    "def validation_one_epoch(val_loader, model, device:str = 'gpu', epoch:int = 0):\n",
    "    running_loss = 0.0\n",
    "\n",
    "    loss_classifier = 0.0\n",
    "    loss_box_reg = 0.0\n",
    "    \n",
    "    metric = MeanAveragePrecision()\n",
    "    preds = []\n",
    "    tag = []\n",
    "\n",
    "    # switch to validation mode\n",
    "    if model.training:\n",
    "        model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "            # iterating over batches in valoader_loader\n",
    "        for i, (images,targets) in tqdm(enumerate(val_loader,0), total = np.ceil(val_loader.dataset.__len__() / val_loader.batch_size)):\n",
    "            images = images.to(device)\n",
    "\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "            predictions = model(images)\n",
    "            \n",
    "            # handle images with no detections\n",
    "            for idx,t in enumerate(targets):\n",
    "                if len(t['boxes']) == 0:\n",
    "                    targets[idx]['boxes'] = torch.tensor([[0,0,0,0]], dtype = torch.float32).to(device)\n",
    "            \n",
    "            #return predictions, targets\n",
    "            metric.update(predictions,targets)\n",
    "            preds.append(predictions)\n",
    "            tag.append(targets)\n",
    "            \n",
    "    #return preds, tag\n",
    "    metrics_values = metric.compute()\n",
    "    \n",
    "    print('\\n')\n",
    "    print(f\"mAP 50: {metrics_values['map_50']:.3f}\\n\")\n",
    "    return  metrics_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OUn2HDfKQ5Io",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 648,
     "referenced_widgets": [
      "a60426f0e7a54d73b6e0c2f9b387014e",
      "fbd19bf4fc474719888a7897f968f3ca",
      "4db956895a3141f28022da95c25f1252",
      "4d7e95b92ba24b5b996797115fb9c1bb",
      "b8fc7d083f9e4e38af1e69dc3554f9ea",
      "e9d3f3543a6f4bbb9882787860f0c58a",
      "1aaae3c9af344b05beec3ac16dad1aad",
      "9df69ad89f8347da8f16c904a72d8292",
      "0f3c06609a5f4fe694828658cf13d739",
      "c11d813e67674c5aa7e610d329a69454",
      "ee3641c36b4b48c392a495895c8b3ce6",
      "d6edaebbb6154f859629d324036af642",
      "6d526ad72b534d93a5a8f76df63df20b",
      "e02c6abcc95e4da0a9cb3cb15ac48f0a",
      "2a718ad8d12b413a8fca8a4472ab98f4",
      "0bc3ca5f6ae14fa2a915acde9d6b1d5f",
      "fc389c8c0bfb468e961e1fd8cfdf4c19",
      "5b7a5e974e734fc283d50c010ac4bf46",
      "f8a14930f543477fafe5530184579b14",
      "d0e3379f092241df86169cf60099f1f7",
      "c2f6b3b6714d4e4594daf9675e5a44b3",
      "00fb8da3cc9a4c5982cb002b9e94c23a",
      "bbfec50483144e2f95d79875d3e07a42",
      "6ae82e6c7e604a4e8beaa182b465cc3c",
      "759b8ff35b634fd3aa7ee83e76c2c313",
      "f00551be3f984a389ed9b220ba00862d",
      "56cc5aa97bd34b209ff884535802cc3e",
      "62401a231ae3417ea29210dbabcecc0b",
      "874078ef228749a48aaedc236ede5588",
      "d12370bd8e524c57bd2cf7eed739b994",
      "ecdf2f706f2c407cbf53fa89334d86d9",
      "f0a42d5ba7e84689ad7cf1ae5e6e0092",
      "7f705f06ff564fdd8a6ce73333ccc490"
     ]
    },
    "id": "OUn2HDfKQ5Io",
    "outputId": "50493aa8-2edd-40de-a403-2621a13a1968"
   },
   "outputs": [],
   "source": [
    "max_epochs = 15\n",
    "losses_train = []\n",
    "mAP_val = []\n",
    "\n",
    "device = 'cuda'\n",
    "model.to(device)\n",
    "\n",
    "best_map = 0.0\n",
    "\n",
    "for e in range(max_epochs):\n",
    "    print(f\"Epoch {e+1}\\n-------------------------------\")\n",
    "\n",
    "    # resample list\n",
    "    train_dl.dataset.trigger_sampling()\n",
    "    # training loop\n",
    "    train_loss = train_one_epoch(\n",
    "    train_loader = train_dl,\n",
    "    model = model,\n",
    "    optimizer = optimizer,\n",
    "    epoch = e,\n",
    "    device = device)\n",
    "\n",
    "    losses_train.append(train_loss)\n",
    "\n",
    "    # validation loop\n",
    "    metrics = validation_one_epoch(\n",
    "        model = model,\n",
    "        val_loader = val_dl,\n",
    "        device = device)\n",
    "\n",
    "    mAP_val.append(metrics['map_50'].numpy())\n",
    "    \n",
    "    if metrics['map_50'] > best_map:\n",
    "        print(f\"Saving best model at epoch {e+1} with mAP50 of {metrics['map_50'].numpy():.3f}\")\n",
    "        best_model = model.state_dict()\n",
    "        best_map = metrics['map_50']"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "interpreter": {
   "hash": "cbc2ccb7899380f8e39344ba6fff5f38db9a0526ef90eff1147cd398f3029ddf"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00fb8da3cc9a4c5982cb002b9e94c23a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0bc3ca5f6ae14fa2a915acde9d6b1d5f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0f3c06609a5f4fe694828658cf13d739": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1aaae3c9af344b05beec3ac16dad1aad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2a718ad8d12b413a8fca8a4472ab98f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c2f6b3b6714d4e4594daf9675e5a44b3",
      "placeholder": "​",
      "style": "IPY_MODEL_00fb8da3cc9a4c5982cb002b9e94c23a",
      "value": " 125/125.0 [00:14&lt;00:00,  8.99it/s]"
     }
    },
    "4d7e95b92ba24b5b996797115fb9c1bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c11d813e67674c5aa7e610d329a69454",
      "placeholder": "​",
      "style": "IPY_MODEL_ee3641c36b4b48c392a495895c8b3ce6",
      "value": " 125/125.0 [00:40&lt;00:00,  3.12it/s]"
     }
    },
    "4db956895a3141f28022da95c25f1252": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9df69ad89f8347da8f16c904a72d8292",
      "max": 125,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0f3c06609a5f4fe694828658cf13d739",
      "value": 125
     }
    },
    "56cc5aa97bd34b209ff884535802cc3e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5b7a5e974e734fc283d50c010ac4bf46": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "62401a231ae3417ea29210dbabcecc0b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6ae82e6c7e604a4e8beaa182b465cc3c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_62401a231ae3417ea29210dbabcecc0b",
      "placeholder": "​",
      "style": "IPY_MODEL_874078ef228749a48aaedc236ede5588",
      "value": " 58%"
     }
    },
    "6d526ad72b534d93a5a8f76df63df20b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fc389c8c0bfb468e961e1fd8cfdf4c19",
      "placeholder": "​",
      "style": "IPY_MODEL_5b7a5e974e734fc283d50c010ac4bf46",
      "value": "100%"
     }
    },
    "759b8ff35b634fd3aa7ee83e76c2c313": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d12370bd8e524c57bd2cf7eed739b994",
      "max": 125,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ecdf2f706f2c407cbf53fa89334d86d9",
      "value": 73
     }
    },
    "7f705f06ff564fdd8a6ce73333ccc490": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "874078ef228749a48aaedc236ede5588": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9df69ad89f8347da8f16c904a72d8292": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a60426f0e7a54d73b6e0c2f9b387014e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fbd19bf4fc474719888a7897f968f3ca",
       "IPY_MODEL_4db956895a3141f28022da95c25f1252",
       "IPY_MODEL_4d7e95b92ba24b5b996797115fb9c1bb"
      ],
      "layout": "IPY_MODEL_b8fc7d083f9e4e38af1e69dc3554f9ea"
     }
    },
    "b8fc7d083f9e4e38af1e69dc3554f9ea": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bbfec50483144e2f95d79875d3e07a42": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6ae82e6c7e604a4e8beaa182b465cc3c",
       "IPY_MODEL_759b8ff35b634fd3aa7ee83e76c2c313",
       "IPY_MODEL_f00551be3f984a389ed9b220ba00862d"
      ],
      "layout": "IPY_MODEL_56cc5aa97bd34b209ff884535802cc3e"
     }
    },
    "c11d813e67674c5aa7e610d329a69454": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c2f6b3b6714d4e4594daf9675e5a44b3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d0e3379f092241df86169cf60099f1f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d12370bd8e524c57bd2cf7eed739b994": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d6edaebbb6154f859629d324036af642": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6d526ad72b534d93a5a8f76df63df20b",
       "IPY_MODEL_e02c6abcc95e4da0a9cb3cb15ac48f0a",
       "IPY_MODEL_2a718ad8d12b413a8fca8a4472ab98f4"
      ],
      "layout": "IPY_MODEL_0bc3ca5f6ae14fa2a915acde9d6b1d5f"
     }
    },
    "e02c6abcc95e4da0a9cb3cb15ac48f0a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f8a14930f543477fafe5530184579b14",
      "max": 125,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d0e3379f092241df86169cf60099f1f7",
      "value": 125
     }
    },
    "e9d3f3543a6f4bbb9882787860f0c58a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ecdf2f706f2c407cbf53fa89334d86d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ee3641c36b4b48c392a495895c8b3ce6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f00551be3f984a389ed9b220ba00862d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f0a42d5ba7e84689ad7cf1ae5e6e0092",
      "placeholder": "​",
      "style": "IPY_MODEL_7f705f06ff564fdd8a6ce73333ccc490",
      "value": " 73/125.0 [00:23&lt;00:16,  3.07it/s]"
     }
    },
    "f0a42d5ba7e84689ad7cf1ae5e6e0092": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f8a14930f543477fafe5530184579b14": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fbd19bf4fc474719888a7897f968f3ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e9d3f3543a6f4bbb9882787860f0c58a",
      "placeholder": "​",
      "style": "IPY_MODEL_1aaae3c9af344b05beec3ac16dad1aad",
      "value": "100%"
     }
    },
    "fc389c8c0bfb468e961e1fd8cfdf4c19": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
